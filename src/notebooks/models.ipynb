{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from unittest.mock import patch\n",
    "\n",
    "from src.model.swin_transformer_v2_pseudo_3d import SwinTransformerV2Pseudo3d, map_pretrained_2d_to_pseudo_3d\n",
    "from src.model.smp import Unet\n",
    "from src.utils.utils import FeatureExtractorWrapper, get_num_layers, get_feature_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2d = timm.create_model(\n",
    "    'swinv2_tiny_window8_256.ms_in1k', \n",
    "    features_only=True,\n",
    "    pretrained=True,\n",
    ")\n",
    "x = torch.randn(1, 3, 256, 256)\n",
    "y = model_2d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with patch('timm.models.swin_transformer_v2.SwinTransformerV2', SwinTransformerV2Pseudo3d):\n",
    "    model_pseudo_3d = timm.create_model(\n",
    "        'swinv2_tiny_window8_256.ms_in1k', \n",
    "        features_only=True,\n",
    "        pretrained=False,\n",
    "        window_size=(8, 8, 16),\n",
    "        img_size=(256, 256, 64),\n",
    "    )\n",
    "x = torch.randn(1, 3, 256, 256, 64)\n",
    "y = model_pseudo_3d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.proj.weight: torch.Size([96, 3, 4, 4]) -> torch.Size([96, 3, 4, 4, 4])\n",
      "patch_embed.proj.bias: torch.Size([96]) -> OK\n",
      "patch_embed.norm.weight: torch.Size([96]) -> OK\n",
      "patch_embed.norm.bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.0.attn.logit_scale: torch.Size([3, 1, 1]) -> OK\n",
      "layers_0.blocks.0.attn.q_bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.0.attn.v_bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.0.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> torch.Size([512, 3])\n",
      "layers_0.blocks.0.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_0.blocks.0.attn.cpb_mlp.2.weight: torch.Size([3, 512]) -> OK\n",
      "layers_0.blocks.0.attn.qkv.weight: torch.Size([288, 96]) -> OK\n",
      "layers_0.blocks.0.attn.proj.weight: torch.Size([96, 96]) -> OK\n",
      "layers_0.blocks.0.attn.proj.bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.0.norm1.weight: torch.Size([96]) -> OK\n",
      "layers_0.blocks.0.norm1.bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.0.mlp.fc1.weight: torch.Size([384, 96]) -> OK\n",
      "layers_0.blocks.0.mlp.fc1.bias: torch.Size([384]) -> OK\n",
      "layers_0.blocks.0.mlp.fc2.weight: torch.Size([96, 384]) -> OK\n",
      "layers_0.blocks.0.mlp.fc2.bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.0.norm2.weight: torch.Size([96]) -> OK\n",
      "layers_0.blocks.0.norm2.bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.1.attn.logit_scale: torch.Size([3, 1, 1]) -> OK\n",
      "layers_0.blocks.1.attn.q_bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.1.attn.v_bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.1.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers_0.blocks.1.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_0.blocks.1.attn.cpb_mlp.2.weight: torch.Size([3, 512]) -> OK\n",
      "layers_0.blocks.1.attn.qkv.weight: torch.Size([288, 96]) -> OK\n",
      "layers_0.blocks.1.attn.proj.weight: torch.Size([96, 96]) -> OK\n",
      "layers_0.blocks.1.attn.proj.bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.1.norm1.weight: torch.Size([96]) -> OK\n",
      "layers_0.blocks.1.norm1.bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.1.mlp.fc1.weight: torch.Size([384, 96]) -> OK\n",
      "layers_0.blocks.1.mlp.fc1.bias: torch.Size([384]) -> OK\n",
      "layers_0.blocks.1.mlp.fc2.weight: torch.Size([96, 384]) -> OK\n",
      "layers_0.blocks.1.mlp.fc2.bias: torch.Size([96]) -> OK\n",
      "layers_0.blocks.1.norm2.weight: torch.Size([96]) -> OK\n",
      "layers_0.blocks.1.norm2.bias: torch.Size([96]) -> OK\n",
      "layers_1.downsample.reduction.weight: torch.Size([192, 384]) -> OK\n",
      "layers_1.downsample.norm.weight: torch.Size([192]) -> OK\n",
      "layers_1.downsample.norm.bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.0.attn.logit_scale: torch.Size([6, 1, 1]) -> OK\n",
      "layers_1.blocks.0.attn.q_bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.0.attn.v_bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.0.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers_1.blocks.0.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_1.blocks.0.attn.cpb_mlp.2.weight: torch.Size([6, 512]) -> OK\n",
      "layers_1.blocks.0.attn.qkv.weight: torch.Size([576, 192]) -> OK\n",
      "layers_1.blocks.0.attn.proj.weight: torch.Size([192, 192]) -> OK\n",
      "layers_1.blocks.0.attn.proj.bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.0.norm1.weight: torch.Size([192]) -> OK\n",
      "layers_1.blocks.0.norm1.bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.0.mlp.fc1.weight: torch.Size([768, 192]) -> OK\n",
      "layers_1.blocks.0.mlp.fc1.bias: torch.Size([768]) -> OK\n",
      "layers_1.blocks.0.mlp.fc2.weight: torch.Size([192, 768]) -> OK\n",
      "layers_1.blocks.0.mlp.fc2.bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.0.norm2.weight: torch.Size([192]) -> OK\n",
      "layers_1.blocks.0.norm2.bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.1.attn.logit_scale: torch.Size([6, 1, 1]) -> OK\n",
      "layers_1.blocks.1.attn.q_bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.1.attn.v_bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.1.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers_1.blocks.1.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_1.blocks.1.attn.cpb_mlp.2.weight: torch.Size([6, 512]) -> OK\n",
      "layers_1.blocks.1.attn.qkv.weight: torch.Size([576, 192]) -> OK\n",
      "layers_1.blocks.1.attn.proj.weight: torch.Size([192, 192]) -> OK\n",
      "layers_1.blocks.1.attn.proj.bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.1.norm1.weight: torch.Size([192]) -> OK\n",
      "layers_1.blocks.1.norm1.bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.1.mlp.fc1.weight: torch.Size([768, 192]) -> OK\n",
      "layers_1.blocks.1.mlp.fc1.bias: torch.Size([768]) -> OK\n",
      "layers_1.blocks.1.mlp.fc2.weight: torch.Size([192, 768]) -> OK\n",
      "layers_1.blocks.1.mlp.fc2.bias: torch.Size([192]) -> OK\n",
      "layers_1.blocks.1.norm2.weight: torch.Size([192]) -> OK\n",
      "layers_1.blocks.1.norm2.bias: torch.Size([192]) -> OK\n",
      "layers_2.downsample.reduction.weight: torch.Size([384, 768]) -> OK\n",
      "layers_2.downsample.norm.weight: torch.Size([384]) -> OK\n",
      "layers_2.downsample.norm.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.0.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers_2.blocks.0.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.0.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.0.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers_2.blocks.0.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_2.blocks.0.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers_2.blocks.0.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers_2.blocks.0.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers_2.blocks.0.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.0.norm1.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.0.norm1.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.0.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers_2.blocks.0.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers_2.blocks.0.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers_2.blocks.0.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.0.norm2.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.0.norm2.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.1.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers_2.blocks.1.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.1.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.1.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers_2.blocks.1.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_2.blocks.1.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers_2.blocks.1.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers_2.blocks.1.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers_2.blocks.1.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.1.norm1.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.1.norm1.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.1.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers_2.blocks.1.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers_2.blocks.1.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers_2.blocks.1.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.1.norm2.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.1.norm2.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.2.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers_2.blocks.2.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.2.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.2.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers_2.blocks.2.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_2.blocks.2.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers_2.blocks.2.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers_2.blocks.2.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers_2.blocks.2.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.2.norm1.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.2.norm1.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.2.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers_2.blocks.2.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers_2.blocks.2.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers_2.blocks.2.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.2.norm2.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.2.norm2.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.3.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers_2.blocks.3.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.3.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.3.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers_2.blocks.3.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_2.blocks.3.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers_2.blocks.3.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers_2.blocks.3.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers_2.blocks.3.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.3.norm1.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.3.norm1.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.3.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers_2.blocks.3.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers_2.blocks.3.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers_2.blocks.3.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.3.norm2.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.3.norm2.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.4.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers_2.blocks.4.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.4.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.4.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers_2.blocks.4.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_2.blocks.4.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers_2.blocks.4.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers_2.blocks.4.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers_2.blocks.4.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.4.norm1.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.4.norm1.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.4.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers_2.blocks.4.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers_2.blocks.4.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers_2.blocks.4.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.4.norm2.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.4.norm2.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.5.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers_2.blocks.5.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.5.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.5.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers_2.blocks.5.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_2.blocks.5.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers_2.blocks.5.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers_2.blocks.5.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers_2.blocks.5.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.5.norm1.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.5.norm1.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.5.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers_2.blocks.5.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers_2.blocks.5.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers_2.blocks.5.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers_2.blocks.5.norm2.weight: torch.Size([384]) -> OK\n",
      "layers_2.blocks.5.norm2.bias: torch.Size([384]) -> OK\n",
      "layers_3.downsample.reduction.weight: torch.Size([768, 1536]) -> OK\n",
      "layers_3.downsample.norm.weight: torch.Size([768]) -> OK\n",
      "layers_3.downsample.norm.bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.0.attn.logit_scale: torch.Size([24, 1, 1]) -> OK\n",
      "layers_3.blocks.0.attn.q_bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.0.attn.v_bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.0.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers_3.blocks.0.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_3.blocks.0.attn.cpb_mlp.2.weight: torch.Size([24, 512]) -> OK\n",
      "layers_3.blocks.0.attn.qkv.weight: torch.Size([2304, 768]) -> OK\n",
      "layers_3.blocks.0.attn.proj.weight: torch.Size([768, 768]) -> OK\n",
      "layers_3.blocks.0.attn.proj.bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.0.norm1.weight: torch.Size([768]) -> OK\n",
      "layers_3.blocks.0.norm1.bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.0.mlp.fc1.weight: torch.Size([3072, 768]) -> OK\n",
      "layers_3.blocks.0.mlp.fc1.bias: torch.Size([3072]) -> OK\n",
      "layers_3.blocks.0.mlp.fc2.weight: torch.Size([768, 3072]) -> OK\n",
      "layers_3.blocks.0.mlp.fc2.bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.0.norm2.weight: torch.Size([768]) -> OK\n",
      "layers_3.blocks.0.norm2.bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.1.attn.logit_scale: torch.Size([24, 1, 1]) -> OK\n",
      "layers_3.blocks.1.attn.q_bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.1.attn.v_bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.1.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers_3.blocks.1.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers_3.blocks.1.attn.cpb_mlp.2.weight: torch.Size([24, 512]) -> OK\n",
      "layers_3.blocks.1.attn.qkv.weight: torch.Size([2304, 768]) -> OK\n",
      "layers_3.blocks.1.attn.proj.weight: torch.Size([768, 768]) -> OK\n",
      "layers_3.blocks.1.attn.proj.bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.1.norm1.weight: torch.Size([768]) -> OK\n",
      "layers_3.blocks.1.norm1.bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.1.mlp.fc1.weight: torch.Size([3072, 768]) -> OK\n",
      "layers_3.blocks.1.mlp.fc1.bias: torch.Size([3072]) -> OK\n",
      "layers_3.blocks.1.mlp.fc2.weight: torch.Size([768, 3072]) -> OK\n",
      "layers_3.blocks.1.mlp.fc2.bias: torch.Size([768]) -> OK\n",
      "layers_3.blocks.1.norm2.weight: torch.Size([768]) -> OK\n",
      "layers_3.blocks.1.norm2.bias: torch.Size([768]) -> OK\n"
     ]
    }
   ],
   "source": [
    "model_2d_state_dict = model_2d.state_dict()\n",
    "model_pseudo_3d_state_dict = model_pseudo_3d.state_dict()\n",
    "for key, value in model_2d_state_dict.items():\n",
    "    if key in model_pseudo_3d_state_dict:\n",
    "        if value.shape == model_pseudo_3d_state_dict[key].shape:\n",
    "            print(f'{key}: {value.shape} -> OK')\n",
    "        else:\n",
    "            print(f'{key}: {value.shape} -> {model_pseudo_3d_state_dict[key].shape}')\n",
    "    else:\n",
    "        print(f'{key}: {value.shape} -> NOT FOUND')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No-matches are `patch_embed.proj` (Conv2d -> Conv3d) and `layers.0.blocks.0.attn.cpb_mlp.0` (relative position bias mapping MLP for Z dim) layers' weights and biases, algthough biases shapes match. \n",
    "\n",
    "- Conv layer's weight: `torch.Size([96, 3, 4, 4]) -> torch.Size([96, 3, 4, 4, 4])`\n",
    "\n",
    "- MLP's weight: `torch.Size([512, 2]) -> torch.Size([512, 3])`\n",
    "\n",
    "For conv layer proposal is to repeat weights along 3rd dimension and scale them down by patch size along Z dim (4) and keep bias term intact. E. g. if the image is just repeated along Z dim, then the 3D patch embedding in such case will be equal to 2D patch embedding of non-repeated patch.\n",
    "\n",
    "For relative position bias proposal is to calculate weights for new dimention as mean of weights of previous two and keep the bias intact. No invariancy for that case.\n",
    "\n",
    "**Note**: it needs additional investigation whether low-rank of the obtained weights is a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.proj.weight: torch.Size([96, 3, 4, 4]) -> torch.Size([96, 3, 4, 4, 4])\n",
      "layers_0.blocks.0.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> torch.Size([512, 3])\n"
     ]
    }
   ],
   "source": [
    "model = map_pretrained_2d_to_pseudo_3d(model_2d, model_pseudo_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 64, 64, 96]),\n",
       " torch.Size([1, 32, 32, 192]),\n",
       " torch.Size([1, 16, 16, 384]),\n",
       " torch.Size([1, 8, 8, 768])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 256, 256, 64)\n",
    "y = model(x)\n",
    "[y_.shape for y_ in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_layers(model), get_num_layers(FeatureExtractorWrapper(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 192, 384, 768), (96, 192, 384, 768))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_channels(model, (3, 256, 256, 64)), \\\n",
    "get_feature_channels(FeatureExtractorWrapper(model), (3, 256, 256, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 384, 192, 96)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_channels(FeatureExtractorWrapper(model), input_shape=(3, 256, 256, 64))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(\n",
    "    encoder=FeatureExtractorWrapper(model),\n",
    "    encoder_channels=get_feature_channels(model, input_shape=(3, 256, 256, 64)),\n",
    "    classes=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): FeatureExtractorWrapper(\n",
       "    (model): FeatureListNet(\n",
       "      (patch_embed): PatchEmbedPseudo3d(\n",
       "        (proj): Conv3d(3, 96, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n",
       "        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (layers_0): SwinTransformerV2StagePseudo3d(\n",
       "        (downsample): Identity()\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttentionPseudo3d(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=3, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): Identity()\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttention(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): DropPath(drop_prob=0.009)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): DropPath(drop_prob=0.009)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers_1): SwinTransformerV2StagePseudo3d(\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttention(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): DropPath(drop_prob=0.018)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): DropPath(drop_prob=0.018)\n",
       "          )\n",
       "          (1): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttention(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): DropPath(drop_prob=0.027)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): DropPath(drop_prob=0.027)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers_2): SwinTransformerV2StagePseudo3d(\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttention(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): DropPath(drop_prob=0.036)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): DropPath(drop_prob=0.036)\n",
       "          )\n",
       "          (1): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttention(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): DropPath(drop_prob=0.045)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): DropPath(drop_prob=0.045)\n",
       "          )\n",
       "          (2): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttention(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): DropPath(drop_prob=0.055)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): DropPath(drop_prob=0.055)\n",
       "          )\n",
       "          (3): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttention(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): DropPath(drop_prob=0.064)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): DropPath(drop_prob=0.064)\n",
       "          )\n",
       "          (4): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttention(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): DropPath(drop_prob=0.073)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): DropPath(drop_prob=0.073)\n",
       "          )\n",
       "          (5): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttention(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): DropPath(drop_prob=0.082)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): DropPath(drop_prob=0.082)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layers_3): SwinTransformerV2StagePseudo3d(\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttention(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): DropPath(drop_prob=0.091)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): DropPath(drop_prob=0.091)\n",
       "          )\n",
       "          (1): SwinTransformerV2BlockPseudo3d(\n",
       "            (attn): WindowAttention(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path1): DropPath(drop_prob=0.100)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (drop_path2): DropPath(drop_prob=0.100)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(1152, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(448, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 256, 256])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 256, 256, 64)\n",
    "y = unet(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrolls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
