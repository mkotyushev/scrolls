{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from unittest.mock import patch\n",
    "\n",
    "from src.model.swin_transformer_v2_pseudo_3d import SwinTransformerV2Pseudo3d, map_pretrained_2d_to_pseudo_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64, 96])\n"
     ]
    }
   ],
   "source": [
    "model_2d = timm.create_model(\n",
    "    'swinv2_tiny_window8_256.ms_in1k', \n",
    "    pretrained=True,\n",
    ").cuda()\n",
    "x = torch.randn(1, 3, 256, 256).cuda()\n",
    "y = model_2d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with patch('timm.models.swin_transformer_v2.SwinTransformerV2', SwinTransformerV2Pseudo3d):\n",
    "    model_pseudo_3d = timm.create_model(\n",
    "        'swinv2_tiny_window8_256.ms_in1k', \n",
    "        pretrained=False,\n",
    "        window_size=(8, 8, 16),\n",
    "        img_size=(256, 256, 64),\n",
    "    ).cuda()\n",
    "x = torch.randn(1, 3, 256, 256, 64).cuda()\n",
    "y = model_pseudo_3d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.proj.weight: torch.Size([96, 3, 4, 4]) -> torch.Size([96, 3, 4, 4, 4])\n",
      "patch_embed.proj.bias: torch.Size([96]) -> OK\n",
      "patch_embed.norm.weight: torch.Size([96]) -> OK\n",
      "patch_embed.norm.bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.0.attn.logit_scale: torch.Size([3, 1, 1]) -> OK\n",
      "layers.0.blocks.0.attn.q_bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.0.attn.v_bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.0.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> torch.Size([512, 3])\n",
      "layers.0.blocks.0.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.0.blocks.0.attn.cpb_mlp.2.weight: torch.Size([3, 512]) -> OK\n",
      "layers.0.blocks.0.attn.qkv.weight: torch.Size([288, 96]) -> OK\n",
      "layers.0.blocks.0.attn.proj.weight: torch.Size([96, 96]) -> OK\n",
      "layers.0.blocks.0.attn.proj.bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.0.norm1.weight: torch.Size([96]) -> OK\n",
      "layers.0.blocks.0.norm1.bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.0.mlp.fc1.weight: torch.Size([384, 96]) -> OK\n",
      "layers.0.blocks.0.mlp.fc1.bias: torch.Size([384]) -> OK\n",
      "layers.0.blocks.0.mlp.fc2.weight: torch.Size([96, 384]) -> OK\n",
      "layers.0.blocks.0.mlp.fc2.bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.0.norm2.weight: torch.Size([96]) -> OK\n",
      "layers.0.blocks.0.norm2.bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.1.attn.logit_scale: torch.Size([3, 1, 1]) -> OK\n",
      "layers.0.blocks.1.attn.q_bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.1.attn.v_bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.1.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers.0.blocks.1.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.0.blocks.1.attn.cpb_mlp.2.weight: torch.Size([3, 512]) -> OK\n",
      "layers.0.blocks.1.attn.qkv.weight: torch.Size([288, 96]) -> OK\n",
      "layers.0.blocks.1.attn.proj.weight: torch.Size([96, 96]) -> OK\n",
      "layers.0.blocks.1.attn.proj.bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.1.norm1.weight: torch.Size([96]) -> OK\n",
      "layers.0.blocks.1.norm1.bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.1.mlp.fc1.weight: torch.Size([384, 96]) -> OK\n",
      "layers.0.blocks.1.mlp.fc1.bias: torch.Size([384]) -> OK\n",
      "layers.0.blocks.1.mlp.fc2.weight: torch.Size([96, 384]) -> OK\n",
      "layers.0.blocks.1.mlp.fc2.bias: torch.Size([96]) -> OK\n",
      "layers.0.blocks.1.norm2.weight: torch.Size([96]) -> OK\n",
      "layers.0.blocks.1.norm2.bias: torch.Size([96]) -> OK\n",
      "layers.1.downsample.reduction.weight: torch.Size([192, 384]) -> OK\n",
      "layers.1.downsample.norm.weight: torch.Size([192]) -> OK\n",
      "layers.1.downsample.norm.bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.0.attn.logit_scale: torch.Size([6, 1, 1]) -> OK\n",
      "layers.1.blocks.0.attn.q_bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.0.attn.v_bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.0.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers.1.blocks.0.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.1.blocks.0.attn.cpb_mlp.2.weight: torch.Size([6, 512]) -> OK\n",
      "layers.1.blocks.0.attn.qkv.weight: torch.Size([576, 192]) -> OK\n",
      "layers.1.blocks.0.attn.proj.weight: torch.Size([192, 192]) -> OK\n",
      "layers.1.blocks.0.attn.proj.bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.0.norm1.weight: torch.Size([192]) -> OK\n",
      "layers.1.blocks.0.norm1.bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.0.mlp.fc1.weight: torch.Size([768, 192]) -> OK\n",
      "layers.1.blocks.0.mlp.fc1.bias: torch.Size([768]) -> OK\n",
      "layers.1.blocks.0.mlp.fc2.weight: torch.Size([192, 768]) -> OK\n",
      "layers.1.blocks.0.mlp.fc2.bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.0.norm2.weight: torch.Size([192]) -> OK\n",
      "layers.1.blocks.0.norm2.bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.1.attn.logit_scale: torch.Size([6, 1, 1]) -> OK\n",
      "layers.1.blocks.1.attn.q_bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.1.attn.v_bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.1.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers.1.blocks.1.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.1.blocks.1.attn.cpb_mlp.2.weight: torch.Size([6, 512]) -> OK\n",
      "layers.1.blocks.1.attn.qkv.weight: torch.Size([576, 192]) -> OK\n",
      "layers.1.blocks.1.attn.proj.weight: torch.Size([192, 192]) -> OK\n",
      "layers.1.blocks.1.attn.proj.bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.1.norm1.weight: torch.Size([192]) -> OK\n",
      "layers.1.blocks.1.norm1.bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.1.mlp.fc1.weight: torch.Size([768, 192]) -> OK\n",
      "layers.1.blocks.1.mlp.fc1.bias: torch.Size([768]) -> OK\n",
      "layers.1.blocks.1.mlp.fc2.weight: torch.Size([192, 768]) -> OK\n",
      "layers.1.blocks.1.mlp.fc2.bias: torch.Size([192]) -> OK\n",
      "layers.1.blocks.1.norm2.weight: torch.Size([192]) -> OK\n",
      "layers.1.blocks.1.norm2.bias: torch.Size([192]) -> OK\n",
      "layers.2.downsample.reduction.weight: torch.Size([384, 768]) -> OK\n",
      "layers.2.downsample.norm.weight: torch.Size([384]) -> OK\n",
      "layers.2.downsample.norm.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.0.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers.2.blocks.0.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.0.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.0.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers.2.blocks.0.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.2.blocks.0.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers.2.blocks.0.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers.2.blocks.0.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers.2.blocks.0.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.0.norm1.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.0.norm1.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.0.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers.2.blocks.0.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers.2.blocks.0.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers.2.blocks.0.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.0.norm2.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.0.norm2.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.1.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers.2.blocks.1.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.1.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.1.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers.2.blocks.1.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.2.blocks.1.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers.2.blocks.1.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers.2.blocks.1.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers.2.blocks.1.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.1.norm1.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.1.norm1.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.1.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers.2.blocks.1.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers.2.blocks.1.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers.2.blocks.1.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.1.norm2.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.1.norm2.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.2.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers.2.blocks.2.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.2.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.2.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers.2.blocks.2.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.2.blocks.2.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers.2.blocks.2.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers.2.blocks.2.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers.2.blocks.2.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.2.norm1.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.2.norm1.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.2.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers.2.blocks.2.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers.2.blocks.2.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers.2.blocks.2.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.2.norm2.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.2.norm2.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.3.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers.2.blocks.3.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.3.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.3.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers.2.blocks.3.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.2.blocks.3.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers.2.blocks.3.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers.2.blocks.3.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers.2.blocks.3.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.3.norm1.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.3.norm1.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.3.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers.2.blocks.3.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers.2.blocks.3.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers.2.blocks.3.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.3.norm2.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.3.norm2.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.4.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers.2.blocks.4.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.4.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.4.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers.2.blocks.4.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.2.blocks.4.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers.2.blocks.4.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers.2.blocks.4.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers.2.blocks.4.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.4.norm1.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.4.norm1.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.4.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers.2.blocks.4.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers.2.blocks.4.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers.2.blocks.4.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.4.norm2.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.4.norm2.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.5.attn.logit_scale: torch.Size([12, 1, 1]) -> OK\n",
      "layers.2.blocks.5.attn.q_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.5.attn.v_bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.5.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers.2.blocks.5.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.2.blocks.5.attn.cpb_mlp.2.weight: torch.Size([12, 512]) -> OK\n",
      "layers.2.blocks.5.attn.qkv.weight: torch.Size([1152, 384]) -> OK\n",
      "layers.2.blocks.5.attn.proj.weight: torch.Size([384, 384]) -> OK\n",
      "layers.2.blocks.5.attn.proj.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.5.norm1.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.5.norm1.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.5.mlp.fc1.weight: torch.Size([1536, 384]) -> OK\n",
      "layers.2.blocks.5.mlp.fc1.bias: torch.Size([1536]) -> OK\n",
      "layers.2.blocks.5.mlp.fc2.weight: torch.Size([384, 1536]) -> OK\n",
      "layers.2.blocks.5.mlp.fc2.bias: torch.Size([384]) -> OK\n",
      "layers.2.blocks.5.norm2.weight: torch.Size([384]) -> OK\n",
      "layers.2.blocks.5.norm2.bias: torch.Size([384]) -> OK\n",
      "layers.3.downsample.reduction.weight: torch.Size([768, 1536]) -> OK\n",
      "layers.3.downsample.norm.weight: torch.Size([768]) -> OK\n",
      "layers.3.downsample.norm.bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.0.attn.logit_scale: torch.Size([24, 1, 1]) -> OK\n",
      "layers.3.blocks.0.attn.q_bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.0.attn.v_bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.0.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers.3.blocks.0.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.3.blocks.0.attn.cpb_mlp.2.weight: torch.Size([24, 512]) -> OK\n",
      "layers.3.blocks.0.attn.qkv.weight: torch.Size([2304, 768]) -> OK\n",
      "layers.3.blocks.0.attn.proj.weight: torch.Size([768, 768]) -> OK\n",
      "layers.3.blocks.0.attn.proj.bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.0.norm1.weight: torch.Size([768]) -> OK\n",
      "layers.3.blocks.0.norm1.bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.0.mlp.fc1.weight: torch.Size([3072, 768]) -> OK\n",
      "layers.3.blocks.0.mlp.fc1.bias: torch.Size([3072]) -> OK\n",
      "layers.3.blocks.0.mlp.fc2.weight: torch.Size([768, 3072]) -> OK\n",
      "layers.3.blocks.0.mlp.fc2.bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.0.norm2.weight: torch.Size([768]) -> OK\n",
      "layers.3.blocks.0.norm2.bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.1.attn.logit_scale: torch.Size([24, 1, 1]) -> OK\n",
      "layers.3.blocks.1.attn.q_bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.1.attn.v_bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.1.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> OK\n",
      "layers.3.blocks.1.attn.cpb_mlp.0.bias: torch.Size([512]) -> OK\n",
      "layers.3.blocks.1.attn.cpb_mlp.2.weight: torch.Size([24, 512]) -> OK\n",
      "layers.3.blocks.1.attn.qkv.weight: torch.Size([2304, 768]) -> OK\n",
      "layers.3.blocks.1.attn.proj.weight: torch.Size([768, 768]) -> OK\n",
      "layers.3.blocks.1.attn.proj.bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.1.norm1.weight: torch.Size([768]) -> OK\n",
      "layers.3.blocks.1.norm1.bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.1.mlp.fc1.weight: torch.Size([3072, 768]) -> OK\n",
      "layers.3.blocks.1.mlp.fc1.bias: torch.Size([3072]) -> OK\n",
      "layers.3.blocks.1.mlp.fc2.weight: torch.Size([768, 3072]) -> OK\n",
      "layers.3.blocks.1.mlp.fc2.bias: torch.Size([768]) -> OK\n",
      "layers.3.blocks.1.norm2.weight: torch.Size([768]) -> OK\n",
      "layers.3.blocks.1.norm2.bias: torch.Size([768]) -> OK\n",
      "norm.weight: torch.Size([768]) -> OK\n",
      "norm.bias: torch.Size([768]) -> OK\n",
      "head.fc.weight: torch.Size([1000, 768]) -> OK\n",
      "head.fc.bias: torch.Size([1000]) -> OK\n"
     ]
    }
   ],
   "source": [
    "model_2d_state_dict = model_2d.state_dict()\n",
    "model_pseudo_3d_state_dict = model_pseudo_3d.state_dict()\n",
    "for key, value in model_2d_state_dict.items():\n",
    "    if key in model_pseudo_3d_state_dict:\n",
    "        if value.shape == model_pseudo_3d_state_dict[key].shape:\n",
    "            print(f'{key}: {value.shape} -> OK')\n",
    "        else:\n",
    "            print(f'{key}: {value.shape} -> {model_pseudo_3d_state_dict[key].shape}')\n",
    "    else:\n",
    "        print(f'{key}: {value.shape} -> NOT FOUND')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No-matches are `patch_embed.proj` (Conv2d -> Conv3d) and `layers.0.blocks.0.attn.cpb_mlp.0` (relative position bias mapping MLP for Z dim) layers' weights and biases, algthough biases shapes match. \n",
    "\n",
    "- Conv layer's weight: `torch.Size([96, 3, 4, 4]) -> torch.Size([96, 3, 4, 4, 4])`\n",
    "\n",
    "- MLP's weight: `torch.Size([512, 2]) -> torch.Size([512, 3])`\n",
    "\n",
    "For conv layer proposal is to repeat weights along 3rd dimension and scale them down by patch size along Z dim (4) and keep bias term intact. E. g. if the image is just repeated along Z dim, then the 3D patch embedding in such case will be equal to 2D patch embedding of non-repeated patch.\n",
    "\n",
    "For relative position bias proposal is to calculate weights for new dimention as mean of weights of previous two and keep the bias intact. No invariancy for that case.\n",
    "\n",
    "**Note**: it needs additional investigation whether low-rank of the obtained weights is a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed.proj.weight: torch.Size([96, 3, 4, 4]) -> torch.Size([96, 3, 4, 4, 4])\n",
      "layers.0.blocks.0.attn.cpb_mlp.0.weight: torch.Size([512, 2]) -> torch.Size([512, 3])\n"
     ]
    }
   ],
   "source": [
    "model = map_pretrained_2d_to_pseudo_3d(model_2d, model_pseudo_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrolls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
