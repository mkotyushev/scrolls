{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ``converters`` are currently experimental. It may not support operations including (but not limited to) Functions in ``torch.nn.functional`` that involved data dimension\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from src.utils.utils import MyLightningCLI, TrainerWandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_to_path = { \n",
    "      0: '/workspace/data/fragments_z_shift_scale/train/1',\n",
    "      1: '/workspace/data/fragments_z_shift_scale_cropped/train/2a',\n",
    "      2: '/workspace/data/fragments_z_shift_scale_cropped/train/2b',\n",
    "      3: '/workspace/data/fragments_z_shift_scale_cropped/train/2c',\n",
    "      4: '/workspace/data/fragments_z_shift_scale_cropped/train/2d',\n",
    "      5: '/workspace/data/fragments_z_shift_scale/train/3',\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_checkpoint_path(checkpoint_dir):\n",
    "    checkpoints = os.listdir(checkpoint_dir)\n",
    "    checkpoints = sorted(\n",
    "        [c for c in checkpoints if c.startswith('epoch=')], \n",
    "        key=lambda x: int(x.split('step=')[1].split('.')[0])\n",
    "    )[-1]\n",
    "    return os.path.join(checkpoint_dir, checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '0', '--data.init_args.z_end', '12', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmkotyushev_\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230601_050448-42p261hk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mkotyushev_/scrolls/runs/42p261hk' target=\"_blank\">apricot-hill-231</a></strong> to <a href='https://wandb.ai/mkotyushev_/scrolls' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mkotyushev_/scrolls' target=\"_blank\">https://wandb.ai/mkotyushev_/scrolls</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mkotyushev_/scrolls/runs/42p261hk' target=\"_blank\">https://wandb.ai/mkotyushev_/scrolls/runs/42p261hk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.92it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4c2a32514c41e998c9d989f039bdb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.025823507457971573    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1915130913257599     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.025823507457971573   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1915130913257599    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '1', '--data.init_args.z_end', '13', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:03,  3.03it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e930ee3cf3d4d5fac754893447919e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04014004021883011    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19416184723377228    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04014004021883011   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19416184723377228   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '2', '--data.init_args.z_end', '14', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.74it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4815a8597e45efa75f3a430f49235f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.038441091775894165    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1933891326189041     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.038441091775894165   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1933891326189041    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '3', '--data.init_args.z_end', '15', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.69it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb8fc12d9e4404b8b64262dec30fd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.024895383045077324    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1926283985376358     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.024895383045077324   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1926283985376358    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '4', '--data.init_args.z_end', '16', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.63it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e21a8b06a0457fa4482fb38ffa81ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.028044823557138443    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.193980410695076     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.028044823557138443   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.193980410695076    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '5', '--data.init_args.z_end', '17', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.68it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d4a72b82084b3bbba71dda725d5ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04400727525353432    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19423308968544006    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04400727525353432   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19423308968544006   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '6', '--data.init_args.z_end', '18', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.68it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d4a46aeef74a7ca9cd899b02fc0b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05318843573331833    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19449160993099213    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05318843573331833   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19449160993099213   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '7', '--data.init_args.z_end', '19', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.69it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae9e36a30724663b78c98042c1cfb3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05260699987411499    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19470056891441345    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05260699987411499   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19470056891441345   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '8', '--data.init_args.z_end', '20', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.69it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cddba3862721459b80e5fea1c227f38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05269802734255791    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1945885270833969     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05269802734255791   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1945885270833969    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '9', '--data.init_args.z_end', '21', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.67it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2280f7189b6e44f2be37b95a251c930c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.054591428488492966    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19589436054229736    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.054591428488492966   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19589436054229736   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '10', '--data.init_args.z_end', '22', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.68it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f462cba9e9a94053a1ea8eea436d5d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05339596047997475    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19718879461288452    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05339596047997475   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19718879461288452   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '11', '--data.init_args.z_end', '23', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.68it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8620a1b9d345e5bfa987c472e7b8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05502307042479515    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19657552242279053    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05502307042479515   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19657552242279053   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '12', '--data.init_args.z_end', '24', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.74it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec13850440045698a722116aab8f93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05663643777370453    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19501587748527527    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05663643777370453   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19501587748527527   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '13', '--data.init_args.z_end', '25', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.66it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8459be60d47d48e786725fdc3b68d0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0452006496489048     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1947137862443924     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0452006496489048    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1947137862443924    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '14', '--data.init_args.z_end', '26', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.69it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d87ef8c1d1e4fad9098533c859ac052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05177144706249237    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1934569776058197     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05177144706249237   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1934569776058197    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '15', '--data.init_args.z_end', '27', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.67it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa2792c96184a289b7e18cb57bc206e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04358994588255882    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19123834371566772    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04358994588255882   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19123834371566772   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '16', '--data.init_args.z_end', '28', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.69it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65ae3445b1d4b07a306c6bc4a6e657b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04912617802619934    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1887800544500351     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04912617802619934   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1887800544500351    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '17', '--data.init_args.z_end', '29', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.69it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9393cc9b62d4046b4bc336ce86cf7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05995691195130348    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18450751900672913    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05995691195130348   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18450751900672913   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '18', '--data.init_args.z_end', '30', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.68it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd332e5a8534425b70dec0e3241132b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06246739998459816    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1802549809217453     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06246739998459816   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1802549809217453    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '19', '--data.init_args.z_end', '31', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.68it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba731f7f90dd448d8a56ee344db8c7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07428047060966492    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1778106987476349     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07428047060966492   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1778106987476349    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '20', '--data.init_args.z_end', '32', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.66it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e3b6968d244994985a6bb9625e9d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12287342548370361    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1744515299797058     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12287342548370361   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1744515299797058    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '21', '--data.init_args.z_end', '33', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.68it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd3d8dd632343959ac6a52ce16b7db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2423110455274582     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.169606015086174     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2423110455274582    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.169606015086174    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '22', '--data.init_args.z_end', '34', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.65it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10c57c31fda4995a600e310e9d927c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3344622850418091     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1622706651687622     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3344622850418091    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1622706651687622    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '23', '--data.init_args.z_end', '35', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.62it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8af5d6b69764763b680e1caa1719ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4525830149650574     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.15457908809185028    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4525830149650574    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.15457908809185028   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '24', '--data.init_args.z_end', '36', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.62it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db078f05ea294290aa1bb9012ec15991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5360507369041443     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14933355152606964    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5360507369041443    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14933355152606964   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '25', '--data.init_args.z_end', '37', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.62it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0f6016656643da8b86f57de7571137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5926066040992737     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14389416575431824    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5926066040992737    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14389416575431824   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '26', '--data.init_args.z_end', '38', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.61it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b4c98945594923b8eb73f8902e8643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6271229982376099     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13987717032432556    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6271229982376099    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13987717032432556   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '27', '--data.init_args.z_end', '39', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.59it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5ad26a7b4f4d61bfcaa3d308b0505b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6419622898101807     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13855795562267303    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6419622898101807    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13855795562267303   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '28', '--data.init_args.z_end', '40', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.58it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f211f6cb0ac34b47b902fe6b1e0c343b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6227459907531738     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13939310610294342    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6227459907531738    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13939310610294342   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '29', '--data.init_args.z_end', '41', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.57it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772e97d5523e403d99557362c870c97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5855653882026672     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14141759276390076    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5855653882026672    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14141759276390076   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '30', '--data.init_args.z_end', '42', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.56it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117cd3aff0bf4ec0ae48e490ae61392f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5401456952095032     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14660918712615967    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5401456952095032    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14660918712615967   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '31', '--data.init_args.z_end', '43', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.54it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc29851f21514568bf47533427d182d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4468889534473419     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.15616317093372345    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4468889534473419    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.15616317093372345   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '32', '--data.init_args.z_end', '44', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.53it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217ef71970a94786a53abb02773a01bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3373813331127167     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.16703246533870697    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3373813331127167    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16703246533870697   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '33', '--data.init_args.z_end', '45', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.52it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619e0187170c4f6eb2f808a7541bcdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.22471144795417786    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17667508125305176    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22471144795417786   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17667508125305176   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '34', '--data.init_args.z_end', '46', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.51it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db869902c84467c913124dee81dfe17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.15324409306049347    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18514202535152435    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.15324409306049347   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18514202535152435   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '35', '--data.init_args.z_end', '47', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.49it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037f11e8484749ec8911579b638a3c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0942944660782814     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19116225838661194    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0942944660782814    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19116225838661194   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '36', '--data.init_args.z_end', '48', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.50it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6061a9815ea4e049c88dbd3a74ab049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.034524720162153244    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19615629315376282    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.034524720162153244   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19615629315376282   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '37', '--data.init_args.z_end', '49', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.43it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfa57b50a5a43cf93c2323e93f6e4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.00475273746997118    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19884128868579865    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.00475273746997118   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19884128868579865   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '38', '--data.init_args.z_end', '50', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.48it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda81682efdd4f8e9e58cd697b93c667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   3.131386165478034e-06   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1993928849697113     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  3.131386165478034e-06  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1993928849697113    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '39', '--data.init_args.z_end', '51', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:05,  2.32it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c13d05378da4d718478f49046003e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19948841631412506    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19948841631412506   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '40', '--data.init_args.z_end', '52', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.48it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ff19439e3a4abe9e0e470390c6822c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19815558195114136    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19815558195114136   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '41', '--data.init_args.z_end', '53', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.47it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffaccf3d45874f94924196547d64ed65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1968330442905426     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1968330442905426    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '42', '--data.init_args.z_end', '54', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.48it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25738a852698424c9088aa8cc3b3f29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19509419798851013    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19509419798851013   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '43', '--data.init_args.z_end', '55', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.45it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01e01b07d534fbb95abbefd2d98945a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1933363378047943     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1933363378047943    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '44', '--data.init_args.z_end', '56', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.43it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87b061e660b4f81b35a8274d31af2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19210343062877655    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19210343062877655   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '45', '--data.init_args.z_end', '57', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.49it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa3f3e4b26d4dd8a703898b15318fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19145305454730988    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19145305454730988   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '46', '--data.init_args.z_end', '58', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.47it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22753ee7714d43d5b00b73c208ebd04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19034628570079803    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19034628570079803   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '47', '--data.init_args.z_end', '59', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.48it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7286ac9ee384987b6ba1e8a83452611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19007188081741333    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19007188081741333   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '48', '--data.init_args.z_end', '60', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.48it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03aaa50db9d54ac8a48ef61ae1413d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18915635347366333    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18915635347366333   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '49', '--data.init_args.z_end', '61', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.50it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03114e032bd419ba9a5d1afd85a67ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18775661289691925    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18775661289691925   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '50', '--data.init_args.z_end', '62', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.52it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ead97d07a7147239894c43cbd0d39da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18730171024799347    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18730171024799347   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '51', '--data.init_args.z_end', '63', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.53it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e57da0a95ae4c98a0c936313632c4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18758516013622284    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18758516013622284   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/scrolls/lib/python3.10/site-packages/lightning/pytorch/cli.py:484: UserWarning: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"f79de5a9-2ca2-4fbb-a02a-3d62bb4d8158\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6806sTYJk3RVLn6A.json'], args=['validate', '--config', '/workspace/scrolls/weights/fold_5/run/files/config_pl.yaml', '--ckpt_path', '/workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt', '--data.init_args.batch_size', '4', '--data.init_args.crop_size_z', '6', '--data.init_args.scale_z_max', '2.0', '--data.init_args.z_start', '52', '--data.init_args.z_end', '64', '--data.init_args.val_dir_indices', '0', '--data.init_args.surface_volume_dirs', '/workspace/data/fragments_z_shift_scale/train/3'].\n",
      "  rank_zero_warn(\n",
      "Global seed set to 0\n",
      "Unknown scale for /workspace/data/fragments_z_shift_scale/train/3, assuming 1.0\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "12it [00:04,  2.67it/s]\n",
      "Restoring states from the checkpoint path at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/scrolls/weights/fold_5/checkpoints/epoch=13-step=392.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9f4a70001446fcb3b28e56bcfef2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           v_f05           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          vl_bce           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18852850794792175    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          v_f05          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         vl_bce          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18852850794792175   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in [5]:\n",
    "    config_path = f'/workspace/scrolls/weights/fold_{fold}/run/files/config_pl.yaml'\n",
    "    ckpt_path = get_best_checkpoint_path(\n",
    "        f'/workspace/scrolls/weights/fold_{fold}/checkpoints'\n",
    "    )\n",
    "\n",
    "    for z_start in range(0, 53):\n",
    "        args = [\n",
    "            'validate',\n",
    "            '--config', config_path,\n",
    "            '--ckpt_path', ckpt_path,\n",
    "            '--data.init_args.batch_size', 4,\n",
    "            '--data.init_args.crop_size_z', 6,\n",
    "            '--data.init_args.scale_z_max', 2.0,\n",
    "            '--data.init_args.z_start', z_start,\n",
    "            '--data.init_args.z_end', z_start + 12,\n",
    "            '--data.init_args.val_dir_indices', 0,\n",
    "            '--data.init_args.surface_volume_dirs', fold_to_path[fold],\n",
    "        ]\n",
    "        args = [str(arg) for arg in args]\n",
    "        cli = MyLightningCLI(\n",
    "            trainer_class=TrainerWandb, \n",
    "            save_config_kwargs={\n",
    "                'config_filename': 'config_pl.yaml',\n",
    "                'overwrite': True,\n",
    "            },\n",
    "            args=args,\n",
    "            run=True,\n",
    "        )\n",
    "        del cli\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrolls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
